{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# Выбросы и новизна\n",
    "\n",
    "https://github.com/yzhao062/anomaly-detection-resources\n",
    "\n",
    "Строго говоря, в анализе данных есть два направления, которые занимаются поиском аномалий:\n",
    "- поиск выбросов (Outlier Detection)\n",
    "- поиск «новизны» (Novelty Detection).\n",
    "\n",
    "Как и выброс, «новый объект» — это объект, который отличается по своим свойствам от объектов (обучающей) выборки.\n",
    "Но  в отличие от выброса, его в самой выборке пока нет (он появится через некоторое время, и задача как раз и заключается в том,\n",
    "чтобы обнаружить его при появлении). Например, если вы анализируете замеры температуры и отбрасываете аномально большие или маленькие,\n",
    "то Вы боретесь с выбросами. А если Вы создаёте алгоритм, который для каждого нового замера оценивает, насколько он похож на прошлые, и выбрасывает\n",
    "аномальные — Вы «боретесь с новизной»."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Выбросы* являются следствием:\n",
    "\n",
    "- ошибок в данных (неточности измерения, округления, неверной записи и т.п.)\n",
    "- наличия шумовых объектов (неверно классифицированных объектов)\n",
    "- присутствия объектов «других» выборок (например, показаниями сломавшегося датчика)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Новизна, как правило, появляется в результате принципиально нового поведения объекта. Скажем, если наши объекты – описания работы системы, то после проникновения в неё вируса объекты становятся «новизной». Ещё пример – описания работы двигателя после поломки. Здесь важно понимать, что «новизна» называется новизной по той причине, что такие описания для нас абсолютно новые, а новые они потому, что мы не можем в обучающей выборке иметь информацию о всевозможных заражениях вирусами или всевозможных поломках. Формирование такой обучающей выборки трудозатратно и часто не имеет смысла. Зато можно набрать достаточно большую выборку примеров нормальной (штатной) работы системы или механизма.\n",
    "\n",
    "Приложений здесь море:\n",
    "\n",
    "- Обнаружение подозрительных банковских операций (Credit-card Fraud)\n",
    "- Обнаружение вторжений (Intrusion Detection)\n",
    "- Обнаружение нестандартных игроков на бирже (инсайдеров)\n",
    "- Обнаружение неполадок в механизмах по показаниям датчиков\n",
    "- Медицинская диагностика (Medical Diagnosis)\n",
    "- Сейсмология"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Основные методы обнаружения выбросов / аномалий\n",
    "\n",
    "1. Статистические тесты\n",
    "2. Модельные тесты\n",
    "3. Итерационные методы\n",
    "4. Метрические методы\n",
    "5. Метод подмены задачи\n",
    "6. Методы машинного обучения\n",
    "7. Ансамбли алгоритмов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Статистические тесты\n",
    "\n",
    "Тесты, направленные на поиски экстремальных значений по каждой переменной:\n",
    "- z-value\n",
    "- kurtosis measure\n",
    "- boxplot\n",
    "- правило 3 сигма\n",
    "\n",
    "Важно понимать, что экстремальное значение и аномалия это разные понятия. Например, в небольшой выборке\n",
    "\n",
    "[1, 39, 2, 1, 101, 2, 1, 100, 1, 3, 101, 1, 3, 100, 101, 100, 100]\n",
    "значение 39 можно считать аномалией, хотя оно не является максимальным или минимальным.\n",
    "Также стоит отметить, что аномалия характеризуется, как правило, не только экстремальными значениями отдельных признаков"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Модельные тесты\n",
    "\n",
    "Идея очень простая – мы строим модель, которая описывает данные.\n",
    "Точки которые сильно отклоняются от модели (на которых модель сильно ошибается) и есть аномалии.\n",
    "При выборе модели мы можем учесть природу задачи, функционал качества и т.п.\n",
    "\n",
    "Такие методы хороши для определения новизны, но хуже работают при поиске выбросов.\n",
    "Действительно, при настройке модели мы используем данные, в которых есть выбросы (и она под них «затачивается»)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Итерационные методы\n",
    "\n",
    "Методы, которые состоят из итераций, на каждой из которых удаляется группа «особо подозрительных объектов».\n",
    "Например, в n-мерном признаковом пространстве можно удалять выпуклую оболочку наших точек-объектов,\n",
    "считая её представителей выбросами.\n",
    "Как правило, методы этой группы достаточно трудоёмки."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Метрические методы\n",
    "\n",
    "В них постулируется существование некоторой метрики в пространстве объектов, которая и помогает найти аномалии.\n",
    "Интуитивно понятно, что у выброса мало соседей, а у типичной точки много.\n",
    "Поэтому хорошей мерой аномальности может служить, например «расстояние до k-го соседа» (см. метод Local Outlier Factor).\n",
    "Здесь используются специфические метрики, например расстояние Махаланобиса.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Методы подмены задачи\n",
    "\n",
    "Когда возникает новая задача, есть большой соблазн решить её старыми методами (ориентированными на уже известные задачи).\n",
    "Например, можно сделать кластеризацию, тогда маленькие кластеры, скорее всего, состоят из аномалий.\n",
    "Если у нас есть частичная информация об аномалиях,\n",
    "то можно решить её как задачу классификации с классами 1 (размеченные аномалии) и 0 (все остальные объекты).\n",
    "Если бы класс 0 состоял только из нормальных объектов, то такое решение было бы совсем законным.\n",
    "В противном случае остаётся надеяться, что недетектированных аномалий в нём немного."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Методы машинного обучения\n",
    "\n",
    "### Метод опорных векторов для одного класса (OneClassSVM)\n",
    "\n",
    "По сути это обычный SVM, который отделяет выборку от начала координат, где в качестве ядра берут только rbf - радиально базисные функции.\n",
    "Именно этот метод помогал долгие годы решать задачу обнаружения поломок сложных механизмов.\n",
    "Полезно помнить, что OneClassSVM это скорее алгоритм поиска новизны, а не выбросов, т.к. «затачивается» под обучающую выборку.\n",
    "\n",
    "Важные параметры реализации ***sklearn.svm.OneClassSVM***:\n",
    "\n",
    "- kernel – ядро (линейное: linear, полиномиальное: poly, радиальные базисные функции: rbf, сигмоидальное: sigmoid, своё заданное)\n",
    "- nu – верхняя граница на %ошибок и нижняя на % опорных векторов (0.5 по умолчанию)\n",
    "- degree – степень для полиномиального ядра\n",
    "- gamma – коэффициент для функции ядра (1/n_features по умолчанию)\n",
    "- coef0 – параметр в функции полиномиального или сигмоидального ядра\n",
    "\n",
    "### Изолирующий лес (IsolationForest)\n",
    "\n",
    "Является одной из вариаций случайного леса:\n",
    "\n",
    "- Состоит из деревьев\n",
    "- Каждое дерево строится до исчерпании выборки\n",
    "- Для построения ветвления в дереве: выбирается случайный признак и случайное расщепление\n",
    "- Для каждого объекта мера его нормальности – среднее арифметическое глубин листьев, в которые он попал (изолировался)\n",
    "\n",
    "Логика алгоритма простая: при описанном «случайном» способе построения деревьев выбросы будут попадать в листья на ранних этапах\n",
    "(на небольшой глубине дерева), т.е. выбросы проще «изолировать»\n",
    "(напомним, что дерево строится до тех пор, пока каждый объект не окажется в отдельном листе).\n",
    "Алгоритм хорошо отлавливает именно выбросы\n",
    "\n",
    "Важные параметры реализации ***sklearn.ensemble.IsolationForest***\n",
    "\n",
    "- n_estimators – число деревьев\n",
    "- max_samples – объём выборки для построения одного дерева (если вещественное число, то процент всей выборки)\n",
    "- contamination – доля выбросов в выборке (для выбора порога)\n",
    "- max_features – число (или %) признаков, которые используются при построении одного дерева (пока работает только со значением 1.0)\n",
    "- bootstrap – включение режима бутстрепа при формировании подвыборки\n",
    "\n",
    "### Эллипсоидальная аппроксимация данных (EllipticEnvelope)\n",
    "\n",
    "Эллипсоидальная аппроксимация данных — из названия понятно, что облако точек моделируется как внутренность эллипсоида.\n",
    "Метод хорошо работает только на одномодальных данных, а совсем хорошо – на нормально распределённых.\n",
    "Степень новизны здесь фактически определяется по расстоянию Махаланобиса."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyOD: унифицированная библиотека для обнаружения выбросов\n",
    "\n",
    "https://pyod.readthedocs.io/en/latest/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from pyod.utils.data import generate_data\n",
    "import numpy as np\n",
    "# Смоделируем датасет, где 10% точек - выбросы / аномалии\n",
    "X_train, X_test, y_train, y_test=generate_data(n_train=200,\n",
    "                                               n_test=100,\n",
    "                                               n_features=5,\n",
    "                                               contamination=0.1,\n",
    "                                               random_state=3,\n",
    "                                               behaviour=\"new\")\n",
    "X_train = X_train * np.random.uniform(0, 1, size=X_train.shape)\n",
    "X_test = X_test * np.random.uniform(0,1, size=X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABOD ROC:0.7944, precision @ rank n:0.6\n"
     ]
    }
   ],
   "source": [
    "# ABOD (Angle-based Outlier Detector)\n",
    "from pyod.models.abod import ABOD\n",
    "clf_name = 'ABOD'\n",
    "clf = ABOD()\n",
    "clf.fit(X_train)\n",
    "test_scores = clf.decision_function(X_test)\n",
    "\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "roc = round(roc_auc_score(y_test, test_scores), ndigits=4)\n",
    "prn = round(precision_n_scores(y_test, test_scores), ndigits=4)\n",
    "print(f'{clf_name} ROC:{roc}, precision @ rank n:{prn}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPOD ROC:0.9611, precision @ rank n:0.8\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "from pyod.models.copod import COPOD\n",
    "clf_name = 'COPOD'\n",
    "clf = COPOD()\n",
    "clf.fit(X_train)\n",
    "test_scores = clf.decision_function(X_test)\n",
    "\n",
    "roc = round(roc_auc_score(y_test, test_scores), ndigits=4)\n",
    "prn = round(precision_n_scores(y_test, test_scores), ndigits=4)\n",
    "print(f'{clf_name} ROC:{roc}, precision @ rank n:{prn}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest ROC:0.8967, precision @ rank n:0.7\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "clf_name = \"forest\"\n",
    "clf = IForest()\n",
    "clf.fit(X_train)\n",
    "\n",
    "test_scores = clf.decision_function(X_test)\n",
    "roc = round(roc_auc_score(y_test, test_scores), ndigits=4)\n",
    "prn = round(precision_n_scores(y_test, test_scores), ndigits=4)\n",
    "print(f'{clf_name} ROC:{roc}, precision @ rank n:{prn}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyCaret\n",
    "\n",
    "Содержит также много готовых реализаций методов поиска аномалий"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Классный ноутбук со всеми методами еще раз\n",
    "https://nbviewer.org/github/DmitrySerg/otus-public/blob/master/OpenLessons/AnomalyDetection/AnomalyDetection_OpenLesson.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}